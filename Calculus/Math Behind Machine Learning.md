---
tags:
- math
- learning
video-url: https://www.youtube.com/watch?v=URtF_UHYBSo&list=WL&index=2
---
## **Math Behind Machine Learning

**Title: Exploring Machine Learning, Human Cognition, and the Art of Understanding Machines**

**Summary Overview**
The conversation between Anil Ananthaswamy and MLC delves deep into the essence of machine learning, touching upon its historical roots, mathematical foundations, current limitations, and potential societal impacts. The interview also offers insights into how machine learning relates to human cognition, the role of mathematics in understanding machine behavior, and the underlying concepts that define the effectiveness of current AI systems like ChatGPT.

**Human vs. Machine Learning**
Ananthaswamy emphasizes that, unlike machines, humans do not learn by having data meticulously labeled for them. Instead, the human brain learns through pattern recognition and contextual understanding, which develops over evolutionary timescales. In a similar vein, AI systems could benefit from self-supervised learning, a breakthrough concept where data is not manually annotated but instead serves as its own label. This mirrors how the human brain often interprets incomplete information by inferring missing details based on existing context.

The underlying mathematics, particularly pattern matching, is what allows modern AI to mimic some aspects of human reasoning. However, as Ananthaswamy points out, this form of reasoning is fundamentally different from human reasoning. Machines use sophisticated pattern-matching techniques, not genuine understanding or reasoning like humans do. The author strongly believes in the importance of more societal roles – such as journalists, policy makers, and those with basic mathematical knowledge – getting involved in understanding and shaping AI technology.

**The Rich History and Elegant Math Behind AI**
Ananthaswamy also reflects on the history of AI, citing the evolution from early single-layer neural networks in the 1950s to today's deep learning models. The conversation navigates through various eras, mentioning support vector machines, kernel methods, and perceptron convergence theorem, which was one of the first simple mathematical proofs that convinced Ananthaswamy of the beauty of machine learning. The interview also sheds light on kernel methods, which project lower-dimensional data into higher dimensions to make otherwise inseparable data easier to classify. The emphasis is on how these concepts, while mathematically complex, are crucial to understanding what these machines are actually doing.

The importance of understanding the foundational math is highlighted throughout the discussion. Ananthaswamy sees a clear gap in society’s general understanding of AI: he argues that without understanding the basic math, it's impossible to recognize why machines work as they do, and more importantly, why they don't always perform perfectly. In deep learning, overparameterization—where the number of model parameters greatly exceeds training instances—is one such concept that does not fit within classical machine learning theory but is an important aspect of the field today.

**Deep Learning's Uncharted Territory: Terra Incognita**
The discussion touches on the unexplained behaviors in deep learning, particularly why heavily overparameterized deep learning systems generalize well in practice, even when they theoretically shouldn’t. This behavior, dubbed "double descent" or "terra incognita," highlights the gaps in our theoretical understanding of AI. The deep learning revolution’s resurgence since the 2000s, thanks to computational power, large data sets, and GPUs, has vastly expanded the capabilities of machine learning.

**The Intricacies of Self-Supervised Learning and Bias in AI**
A significant part of the conversation is dedicated to the concept of self-supervised learning, where models learn from data without manual labels. Ananthaswamy explains that this method offers a rich way for machines to learn, capturing the nuanced statistical relationships within the data—akin to the way humans learn about the world naturally. Supervised learning, on the other hand, is limited by the biases inherent in human-labeled data, which can often lead to AI systems that perpetuate those biases.

Ananthaswamy addresses the risks AI poses to society, such as potential job disruptions and the perpetuation of societal biases. Machine learning systems often reflect the biases present in their training data, posing challenges to ethical AI usage. The certainty with which large language models like ChatGPT present answers can also mislead users, especially since people are psychologically susceptible to confidently stated misinformation.

**AI, Reasoning, and Emergent Behavior**
Ananthaswamy discusses the nature of machine learning models’ reasoning capabilities, asserting that while deep learning models exhibit behaviors that appear as reasoning, they are fundamentally different from human reasoning. Machine learning is fundamentally a correlation-based process, whereas human reasoning involves abstraction, applying learned principles across different domains. Emergent behavior—observed capabilities appearing as models scale up—is also explored, with Ananthaswamy dismissing the idea that these are inherently mysterious or magical, instead attributing them to the increased complexity of the models.

**The Challenges and Future of AI**
The conversation also explores the limitations of AI and its challenges moving forward. Ananthaswamy mentions the curse of dimensionality, which describes how high-dimensional spaces can make similarity metrics, crucial for algorithms like k-nearest neighbors, less effective. He also shares his perspective on agency and intelligence in AI, emphasizing that while current AI systems may appear intelligent, this "intelligence" is quite different from the embodied, evolving intelligence seen in biological organisms like humans.

The conversation ends on the note that the future of AI may not necessarily be in scaling up deep learning models, but instead integrating symbolic reasoning, biomimetic methods, and possibly a combination of self-supervised learning and reinforcement learning to better simulate human-like cognition.

[[Learning]]  [[Math]]  