---
tags:
- machine-learning
- learning
video-url: https://www.youtube.com/watchv=Fa_V9fP2tpU&list=WL&index=2&t=136s
---

## **Machine Learning Terms

### **1. Artificial Intelligence (AI)**

- Refers to the capability of machines to perform tasks that typically require human intelligence, such as understanding language, recognizing images, solving problems, or making decisions.

### **2. Machine Learning (ML)**

- A subset of AI that enables computers to learn from data and improve performance on tasks over time without explicit programming for each task.

### **3. Algorithm**

- A set of well-defined instructions or rules a computer follows to solve a problem or perform a task.

### **4. Data**

- Information collected and processed by algorithms, including numbers, text, images, or any form of input for analysis.

### **5. Model**

- A mathematical representation trained to recognize patterns in data and make predictions or classifications based on those patterns.

### **6. Training Data**

- A subset of data used to teach a machine learning model how to make predictions by identifying patterns and relationships.

### **7. Test Data**

- A separate subset of data used to evaluate a model’s performance on examples it hasn’t seen during training.

### **8. Supervised Learning**

- A machine learning approach where models learn from labeled data, meaning the input examples have corresponding correct outputs.

### **9. Unsupervised Learning**

- A machine learning approach where models find patterns and structure in unlabeled data, without being given correct answers.

### **10. Reinforcement Learning**

- A branch of machine learning where models learn through trial and error, receiving rewards for good decisions and penalties for poor ones.

### **11. Feature**

- A measurable property or characteristic used as input for a model (e.g., square footage in house price prediction).

### **12. Feature Engineering**

- The process of creating or modifying features to improve a model's performance.

### **13. Feature Scaling**

- Normalizing or standardizing numeric features to a similar scale to ensure effective model training.

### **14. Dimensionality**

- The number of features in a dataset. High dimensionality can cause challenges, often addressed by dimensionality reduction techniques.

### **15. Target**

- The variable or output that a model is trying to predict based on features (e.g., house price).

### **16. Instance**

- A single example or row of data in a dataset, containing all features and the target value (if applicable).

### **17. Label**

- The correct output associated with an instance in supervised learning, used to train the model.

### **18. Model Complexity**

- The sophistication of a model, with more complex models capturing intricate patterns and simpler models capturing basic patterns.

### **19. Bias**

- Refers to errors introduced by overly simplistic assumptions in a model, often resulting in underfitting.

### **20. Variance**

- Refers to a model's sensitivity to variations in training data, often leading to overfitting.

### **21. Bias-Variance Tradeoff**

- The balance between minimizing bias and variance to achieve optimal model performance.

### **22. Noise**

- Random variations or errors in data that do not represent true underlying patterns.

### **23. Overfitting**

- When a model learns the noise in training data, resulting in poor generalization to new data.

### **24. Underfitting**

- When a model is too simple to capture important patterns in data, leading to poor performance.

### **25. Validation**

- Evaluating a model's performance on a validation set, a portion of the training data held out to simulate unseen data.

### **26. Cross-Validation**

- A technique where data is split into multiple subsets, and the model is trained and validated on different splits to ensure robustness.

### **27. Regularization**

- Techniques to prevent overfitting by adding penalties for complexity to the model's parameters.

### **28. Batch**

- A subset of training data processed together in a single step of model training.

### **29. Iteration**

- A single pass through one batch of data during training, leading to an update of model parameters.

### **30. Epoch**

- A complete pass through the entire training dataset during model training.

### **31. Parameter**

- Values that a model learns from data during training, such as weights in a neural network.

### **32. Hyperparameter**

- Configuration settings defined before training begins, such as learning rate, batch size, or the number of epochs.

### **33. Cost Function**

- A function that quantifies the error between the model’s predictions and the true values. The goal is to minimize this function during training.

### **34. Gradient Descent**

- An optimization algorithm that iteratively adjusts model parameters to minimize the cost function by following the steepest descent.

### **35. Learning Rate**

- A hyperparameter that determines the step size for parameter updates during gradient descent.

### **36. Evaluation**

- The process of assessing model performance on unseen data using metrics like accuracy, precision, recall, or mean squared error.

[[Machine learning]]  [[Learning]]